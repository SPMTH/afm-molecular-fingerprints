{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24f7d32",
   "metadata": {},
   "source": [
    "Analysis of the error of regression models depending on the corrugation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d5b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu121\n",
      "Experiment name: debug_regression\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'Evaluate models and create JSON of metrics'\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# IMPORTS\n",
    "# additional packages\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "USER = os.getenv('USER')\n",
    "sys.path.append('../../.')\n",
    "\n",
    "# torch packages\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet50, ResNet50_Weights, efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MultilabelRecall, MultilabelPrecision, MultilabelF1Score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# custom functions\n",
    "from utils.all_utils import train_test_split, compute_pos_weights, train_for_epoch, save_config, validate, \\\n",
    "                            balance_beta_pos_weights, tanimoto_torch, validate_regression\n",
    "\n",
    "from utils.models import resnet_10_chan, effnet_10_chan, eff_net_bias_warmer, regressor_from_checkpoint, \\\n",
    "                            AtomCountPredictor\n",
    "\n",
    "\n",
    "from utils.dataloader import  QUAM_atom_regressor_10_imgs, dataset_ks_dict, parse_k1_to_k, parse_val_ks\n",
    "\n",
    "from utils.evaluation import virtual_epoch_paths\n",
    "\n",
    "\n",
    "\n",
    "class configuration:\n",
    "    def __init__(self):\n",
    "        # EXPERIMENT PARAMETERS\n",
    "        self.experiment_name = 'debug_regression'\n",
    "        self.n_fp = 1024  # number of fingerprints of the backbone model\n",
    "        self.output_size = 10 # output size of regressor model\n",
    "        self.ratio = 0.95  # train/test ratio\n",
    "        self.seed = 42\n",
    "        self.virtual_epochs = 10 # number of times we save the model per epoch. If equal to 1\n",
    "                                # we only save at the end of each epoch.\n",
    "        self.tqdm_flag = True\n",
    "\n",
    "        # TRAINING PARAMETERS\n",
    "\n",
    "        self.lr = 0.001  # learning rate\n",
    "        self.dropout = 0.5\n",
    "        # self.momentum = 0.9  # momentum of SGD optimizer\n",
    "        self.weight_decay = 0  # L2 regularization constant\n",
    "        self.batch_size = 50  # Training batch size\n",
    "        self.test_batch_size = 50  # Test batch size\n",
    "        self.epochs = 100  # Number of epochs\n",
    "        self.bias_warmer = True # setting appropiate bias\n",
    "        self.pos_weight_balancer = True #for bigger fingerprints, it helps balance precision and recall\n",
    "        self.pos_weight_beta = 10\n",
    "        # DATA AUGMENTATION PARAMETERS\n",
    "\n",
    "        # Rotation\n",
    "        self.rot_prob = 0.5  # prob of rotation in data augmentation\n",
    "        self.max_deg = 180  # maximum degrees of rotation in data augmentation\n",
    "\n",
    "        # Zoom\n",
    "        self.zoom_prob = 0.7  # prob of applying zoom\n",
    "        self.max_zoom = 0.7  # maximum zooming in/out\n",
    "\n",
    "        # Translation\n",
    "        self.shift_prob = 0.3  # probability of vertical or/and horizontal translation\n",
    "        self.max_shift = 20  # translation\n",
    "\n",
    "        # Shear\n",
    "        self.shear_prob = 0.3  # probability of shearing\n",
    "        self.max_shear = 10  # maximum shearing angle\n",
    "\n",
    "        # Gaussian noise\n",
    "        self.gauss_noise = 2 # std of gaussian noise\n",
    "\n",
    "        # comments\n",
    "        self.comments = 'It uses all K folders'\n",
    "\n",
    "        # METRICS AND MODELS PATHS\n",
    "        self.exp_path = os.path.join('./models', self.experiment_name)\n",
    "        self.metrics_path = os.path.join(self.exp_path, 'metrics')\n",
    "        self.models_path = os.path.join(self.exp_path, 'models')\n",
    "\n",
    "\n",
    "\n",
    "## Create arguments object\n",
    "args = configuration()\n",
    "# Print experiment name\n",
    "print('Experiment name:', args.experiment_name)\n",
    "# Set random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True  # fix the GPU to deterministic mode\n",
    "torch.manual_seed(args.seed)  # CPU seed\n",
    "torch.cuda.manual_seed_all(args.seed)  # GPU seed\n",
    "random.seed(args.seed)  # python seed for image transformation\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# Load data\n",
    "\n",
    "data_path = '../../data/dataset/atoms_count_w_H_df.gz'\n",
    "dataset_df = pd.read_pickle(data_path)\n",
    "\n",
    "test_df = dataset_df[dataset_df['split'] == 'test']\n",
    "test_k_df = parse_val_ks(test_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0bd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('../../data/calculations/atom_count_preds.npz')\n",
    "\n",
    "loaded_test_predictions = loaded_data['test_predictions']\n",
    "loaded_ground_truth = loaded_data['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f11a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279848, 10) (279848, 10)\n"
     ]
    }
   ],
   "source": [
    "print(loaded_test_predictions.shape, loaded_ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949c0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = loaded_test_predictions\n",
    "ground_truth = loaded_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6cf31",
   "metadata": {},
   "source": [
    "### Compute classification accuracy and regression metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02e1d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CID   C  Br  Cl  F  I  N  O  P  S   H split  \\\n",
      "1    10001048  25   0   0  0  0  6  0  0  0  16  test   \n",
      "7       10005   2   0   0  0  0  4  0  0  0   4  test   \n",
      "14  100128716  15   0   0  0  0  3  0  0  0  21  test   \n",
      "15  100175925  10   0   0  0  0  3  4  0  2   9  test   \n",
      "16  100197007  18   0   0  0  0  3  4  0  2  13  test   \n",
      "18  100197976  20   0   0  0  0  2  3  0  1  14  test   \n",
      "23     228827   7   0   0  0  0  6  2  0  0   8  test   \n",
      "24     228834  14   0   0  0  0  8  4  0  0   8  test   \n",
      "25   22886611  11   0   0  0  0  0  1  0  1  12  test   \n",
      "27   22886614  14   0   0  0  0  0  0  0  1  12  test   \n",
      "\n",
      "                                                 path  \n",
      "1   /scratch/dataset/quam/K-1/Conformer3D_CID_1000...  \n",
      "7   /scratch/dataset/quam/K-1/Conformer3D_CID_1000...  \n",
      "14  /scratch/dataset/quam/K-1/Conformer3D_CID_1001...  \n",
      "15  /scratch/dataset/quam/K-1/Conformer3D_CID_1001...  \n",
      "16  /scratch/dataset/quam/K-1/Conformer3D_CID_1001...  \n",
      "18  /scratch/dataset/quam/K-1/Conformer3D_CID_1001...  \n",
      "23  /scratch/dataset/quam/K-1/Conformer3D_CID_2288...  \n",
      "24  /scratch/dataset/quam/K-1/Conformer3D_CID_2288...  \n",
      "25  /scratch/dataset/quam/K-1/Conformer3D_CID_2288...  \n",
      "27  /scratch/dataset/quam/K-1/Conformer3D_CID_2288...  \n",
      "[[25.  0.  0.  0.  0.  6.  0.  0.  0. 16.]\n",
      " [ 2.  0.  0.  0.  0.  4.  0.  0.  0.  4.]\n",
      " [15.  0.  0.  0.  0.  3.  0.  0.  0. 21.]\n",
      " [10.  0.  0.  0.  0.  3.  4.  0.  2.  9.]\n",
      " [18.  0.  0.  0.  0.  3.  4.  0.  2. 13.]\n",
      " [20.  0.  0.  0.  0.  2.  3.  0.  1. 14.]\n",
      " [ 7.  0.  0.  0.  0.  6.  2.  0.  0.  8.]\n",
      " [14.  0.  0.  0.  0.  8.  4.  0.  0.  8.]\n",
      " [11.  0.  0.  0.  0.  0.  1.  0.  1. 12.]\n",
      " [14.  0.  0.  0.  0.  0.  0.  0.  1. 12.]]\n",
      "[[25.  0.  0.  0.  0.  6.  0.  0.  0. 16.]\n",
      " [ 2.  0.  0.  0.  0.  4.  0.  0.  0.  4.]\n",
      " [15.  0.  0.  0.  0.  3.  0.  0.  0. 21.]\n",
      " [10.  0.  0.  0.  0.  3.  4.  0.  2.  9.]\n",
      " [18.  0.  0.  0.  0.  3.  4.  0.  2. 13.]\n",
      " [20.  0.  0.  0.  0.  2.  3.  0.  1. 14.]\n",
      " [ 7.  0.  0.  0.  0.  6.  2.  0.  0.  8.]\n",
      " [14.  0.  0.  0.  0.  8.  4.  0.  0.  8.]\n",
      " [11.  0.  0.  0.  0.  0.  1.  0.  1. 12.]\n",
      " [14.  0.  0.  0.  0.  0.  0.  0.  1. 12.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_k_df.iloc[:10])\n",
    "print(ground_truth[:10])\n",
    "print(test_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db9f31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C     0.000036\n",
       "Br    0.823697\n",
       "Cl    0.758072\n",
       "F     0.817633\n",
       "I     0.959900\n",
       "N     0.079147\n",
       "O     0.215213\n",
       "P     0.998867\n",
       "S     0.752977\n",
       "H     0.000386\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_k_df[['C', 'Br', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'H']]<1).sum()/len(test_k_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14f0134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.57336840e-05, 8.23697150e-01, 7.58072239e-01, 8.17633144e-01,\n",
       "       9.59899660e-01, 7.91465367e-02, 2.15213259e-01, 9.98867242e-01,\n",
       "       7.52976616e-01, 3.85923787e-04])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ground_truth<1).sum(axis=0)/len(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffeb3a6",
   "metadata": {},
   "source": [
    "#### Compute classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c60a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f1a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 16.20it/s]\n"
     ]
    }
   ],
   "source": [
    "atom_list = ['C', 'Br', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'H']\n",
    "gt_class = (ground_truth>0)\n",
    "pred_class = (test_predictions>0)\n",
    "class_atom_dict = dict()\n",
    "for i, atom in tqdm(enumerate(atom_list)):\n",
    "    prec, recall, f1_score, _ = precision_recall_fscore_support(gt_class[:, i], pred_class[:, i], average='binary')\n",
    "    class_atom_dict[atom] = {'precision': prec, \n",
    "                             'recall': recall, \n",
    "                             'f1_score': f1_score}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c67089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': {'precision': 0.99996426618831,\n",
       "  'recall': 0.9999964265039059,\n",
       "  'f1_score': 0.9999803460875314},\n",
       " 'Br': {'precision': 0.9993504780075912,\n",
       "  'recall': 0.9979123596416555,\n",
       "  'f1_score': 0.9986309010699254},\n",
       " 'Cl': {'precision': 0.9986270630960465,\n",
       "  'recall': 0.9991433171351344,\n",
       "  'f1_score': 0.9988851234116701},\n",
       " 'F': {'precision': 0.9984897815086494,\n",
       "  'recall': 0.9975311061036544,\n",
       "  'f1_score': 0.998010213583478},\n",
       " 'I': {'precision': 0.995906744972415,\n",
       "  'recall': 0.9973266797362323,\n",
       "  'f1_score': 0.9966162065894925},\n",
       " 'N': {'precision': 0.9994295183504931,\n",
       "  'recall': 0.9993441961358018,\n",
       "  'f1_score': 0.9993868554220607},\n",
       " 'O': {'precision': 0.9990984181336344,\n",
       "  'recall': 0.9990665737793745,\n",
       "  'f1_score': 0.9990824957027559},\n",
       " 'P': {'precision': 0.8884297520661157,\n",
       "  'recall': 0.6782334384858044,\n",
       "  'f1_score': 0.7692307692307693},\n",
       " 'S': {'precision': 0.9979878984395356,\n",
       "  'recall': 0.9973093781191685,\n",
       "  'f1_score': 0.9976485229106221},\n",
       " 'H': {'precision': 0.9999320827018217,\n",
       "  'recall': 0.9999749767641382,\n",
       "  'f1_score': 0.9999535292729833}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_atom_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a76ac4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Atom Classification Scores}\n",
      "\\begin{tabular}{cccc}\n",
      "Atom & Precision & Recall & F1 Score \\\\\n",
      "\\hline\n",
      "C & 1.0000 & 1.0000 & 1.0000 \\\\\n",
      "Br & 0.9994 & 0.9979 & 0.9986 \\\\\n",
      "Cl & 0.9986 & 0.9991 & 0.9989 \\\\\n",
      "F & 0.9985 & 0.9975 & 0.9980 \\\\\n",
      "I & 0.9959 & 0.9973 & 0.9966 \\\\\n",
      "N & 0.9994 & 0.9993 & 0.9994 \\\\\n",
      "O & 0.9991 & 0.9991 & 0.9991 \\\\\n",
      "P & 0.8884 & 0.6782 & 0.7692 \\\\\n",
      "S & 0.9980 & 0.9973 & 0.9976 \\\\\n",
      "H & 0.9999 & 1.0000 & 1.0000 \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_latex_table(class_atom_dict):\n",
    "    headers = ['Atom', 'Precision', 'Recall', 'F1 Score']\n",
    "    rows = []\n",
    "\n",
    "    for atom, scores in class_atom_dict.items():\n",
    "        precision = \"{:.4f}\".format(scores['precision'])\n",
    "        recall = \"{:.4f}\".format(scores['recall'])\n",
    "        f1_score = \"{:.4f}\".format(scores['f1_score'])\n",
    "        row = f\"{atom} & {precision} & {recall} & {f1_score} \\\\\\\\\"\n",
    "        rows.append(row)\n",
    "\n",
    "    latex_table = \"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Atom Classification Scores}\\n\\\\begin{tabular}{cccc}\\n\"\n",
    "    latex_table += \" & \".join(headers) + \" \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "    latex_table += \"\\n\".join(rows)\n",
    "    latex_table += \"\\n\\\\end{tabular}\\n\\\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "table = create_latex_table(class_atom_dict)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9822e9c2",
   "metadata": {},
   "source": [
    "#### Compute mse and pearson correlation for each atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ecc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/mgonzalez/.conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import r_regression\n",
    "atom_list = ['C', 'Br', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'H']\n",
    "reg_metrics_atom = dict()\n",
    "for i, atom in enumerate(atom_list):\n",
    "    mse = mean_squared_error(ground_truth[:, i], test_predictions[:, i])\n",
    "    mae = mean_absolute_error(ground_truth[:, i], test_predictions[:, i])\n",
    "    pearson_r = r_regression(ground_truth[:, i].reshape(-1, 1), test_predictions[:, i].reshape(-1, 1))\n",
    "    reg_metrics_atom[atom] = {'mse': mse, \n",
    "                              'mae':mae, \n",
    "                              ''' Pearson's r''': pearson_r[0]}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598ef736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': {'mse': 0.013803923,\n",
       "  'mae': 0.01150982,\n",
       "  \" Pearson's r\": 0.9995503226680649},\n",
       " 'Br': {'mse': 0.00072539377,\n",
       "  'mae': 0.0006682199,\n",
       "  \" Pearson's r\": 0.9983419914335004},\n",
       " 'Cl': {'mse': 0.00095051597,\n",
       "  'mae': 0.000814728,\n",
       "  \" Pearson's r\": 0.9987663905346181},\n",
       " 'F': {'mse': 0.0024227437,\n",
       "  'mae': 0.0014793745,\n",
       "  \" Pearson's r\": 0.9970752120528198},\n",
       " 'I': {'mse': 0.00045381777,\n",
       "  'mae': 0.00035376346,\n",
       "  \" Pearson's r\": 0.9953695154896979},\n",
       " 'N': {'mse': 0.01153126,\n",
       "  'mae': 0.00885838,\n",
       "  \" Pearson's r\": 0.997658606678373},\n",
       " 'O': {'mse': 0.007343272,\n",
       "  'mae': 0.0058067236,\n",
       "  \" Pearson's r\": 0.9978331883561562},\n",
       " 'P': {'mse': 0.000543152,\n",
       "  'mae': 0.00050027156,\n",
       "  \" Pearson's r\": 0.7854063683990198},\n",
       " 'S': {'mse': 0.0022619423,\n",
       "  'mae': 0.001775964,\n",
       "  \" Pearson's r\": 0.9962425755826927},\n",
       " 'H': {'mse': 0.016148051,\n",
       "  'mae': 0.012145879,\n",
       "  \" Pearson's r\": 0.9992578732293284}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_metrics_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeb1d697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Atom Regression Scores}\n",
      "\\begin{tabular}{ccc}\n",
      "Atom & MAE & Pearson's r \\\\\n",
      "\\hline\n",
      "C & 0.0115 & 0.9996 \\\\\n",
      "Br & 0.0007 & 0.9983 \\\\\n",
      "Cl & 0.0008 & 0.9988 \\\\\n",
      "F & 0.0015 & 0.9971 \\\\\n",
      "I & 0.0004 & 0.9954 \\\\\n",
      "N & 0.0089 & 0.9977 \\\\\n",
      "O & 0.0058 & 0.9978 \\\\\n",
      "P & 0.0005 & 0.7854 \\\\\n",
      "S & 0.0018 & 0.9963 \\\\\n",
      "H & 0.0121 & 0.9993 \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "def create_table_latex_v2(data_dict):\n",
    "    headers = ['Atom', 'MAE', \"Pearson's r\"]\n",
    "    rows = []\n",
    "\n",
    "    for atom, values in data_dict.items():\n",
    "        mae = \"{:.4f}\".format(values['mae'])\n",
    "        pearson_r = \"{:.4f}\".format(values[\" Pearson's r\"])\n",
    "        row = f\"{atom} & {mae} & {pearson_r} \\\\\\\\\"\n",
    "        rows.append(row)\n",
    "\n",
    "    latex_table = \"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Atom Regression Scores}\\n\\\\begin{tabular}{ccc}\\n\"\n",
    "    latex_table += \" & \".join(headers) + \" \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "    latex_table += \"\\n\".join(rows)\n",
    "    latex_table += \"\\n\\\\end{tabular}\\n\\\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "table = create_table_latex_v2(reg_metrics_atom)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66981b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': {'mse': 0.013803923,\n",
       "  'mae': 0.01150982,\n",
       "  \" Pearson's r\": 0.9995503226680649},\n",
       " 'Br': {'mse': 0.00072539377,\n",
       "  'mae': 0.0006682199,\n",
       "  \" Pearson's r\": 0.9983400801930626},\n",
       " 'Cl': {'mse': 0.00095051597,\n",
       "  'mae': 0.000814728,\n",
       "  \" Pearson's r\": 0.9987638843927912},\n",
       " 'F': {'mse': 0.0024227437,\n",
       "  'mae': 0.0014793745,\n",
       "  \" Pearson's r\": 0.9970718153314084},\n",
       " 'I': {'mse': 0.00045381777,\n",
       "  'mae': 0.00035376346,\n",
       "  \" Pearson's r\": 0.9953778918543514},\n",
       " 'N': {'mse': 0.01153126,\n",
       "  'mae': 0.00885838,\n",
       "  \" Pearson's r\": 0.9976658766818135},\n",
       " 'O': {'mse': 0.007343272,\n",
       "  'mae': 0.0058067236,\n",
       "  \" Pearson's r\": 0.9978421341892169},\n",
       " 'P': {'mse': 0.000543152,\n",
       "  'mae': 0.00050027156,\n",
       "  \" Pearson's r\": 0.7854038516591924},\n",
       " 'S': {'mse': 0.0022619423,\n",
       "  'mae': 0.001775964,\n",
       "  \" Pearson's r\": 0.9962548491054385},\n",
       " 'H': {'mse': 0.016148051,\n",
       "  'mae': 0.012145879,\n",
       "  \" Pearson's r\": 0.9992569638280011}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_metrics_atom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
